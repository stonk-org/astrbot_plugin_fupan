import json
import os
from datetime import datetime, time
from typing import Optional

import exchange_calendars as xcals
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, filter, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.core.star.star_tools import StarTools


@register(
    "astrbot_plugin_fupan",
    "zanderzhng",
    "å¤ç›˜æ‰“å¡æ’ä»¶ï¼Œç”¨äºå¸®åŠ©äº¤æ˜“è€…è¿›è¡Œæ¯æ—¥å¤ç›˜æ‰“å¡ã€‚æ”¯æŒäº¤æ˜“æ—¥åˆ¤æ–­ã€æ—¶é—´çª—å£æ§åˆ¶ã€æ•°æ®ç»Ÿè®¡ç­‰åŠŸèƒ½ã€‚",
    "1.0.0",
)
class FuPanPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.context = context
        self.config = config

        # åˆå§‹åŒ–äº¤æ˜“æ‰€æ—¥å† (ä½¿ç”¨ä¸­å›½Aè‚¡æ—¥å†)
        self.xcal = xcals.get_calendar("XSHG")  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€æ—¥å†

        # è·å–æ’ä»¶æ•°æ®ç›®å½• (ä½¿ç”¨ AstrBot å®˜æ–¹æä¾›çš„æŒä¹…åŒ–æ•°æ®ç›®å½•)
        self.data_dir = str(StarTools.get_data_dir("astrbot_plugin_fupan"))
        logger.info(f"å¤ç›˜æ‰“å¡æ’ä»¶å·²åŠ è½½ï¼Œæ•°æ®ç›®å½•: {self.data_dir}")

        # åˆå§‹åŒ–APSchedulerç”¨äºå®šæ—¶å¹¿æ’­
        self.scheduler = AsyncIOScheduler()

        # å­˜å‚¨ç¾¤ç»„ä¼šè¯ä¿¡æ¯ç”¨äºå¹¿æ’­
        self.group_sessions = self.load_group_sessions()

        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start()

        # æ·»åŠ æ¯æ—¥9:00çš„å¹¿æ’­ä»»åŠ¡
        self.scheduler.add_job(
            self.send_daily_review,
            "cron",
            hour=9,
            minute=0,
            misfire_grace_time=60,
            id="fupan_daily_review"
        )

    def get_checkin_data_file(self, user_id: str, group_id: Optional[str] = None) -> str:
        """è·å–ç”¨æˆ·æ‰“å¡æ•°æ®æ–‡ä»¶è·¯å¾„"""
        if group_id:
            return os.path.join(self.data_dir, f"checkin_{user_id}_group_{group_id}.json")
        else:
            return os.path.join(self.data_dir, f"checkin_{user_id}_dm.json")

    def save_group_sessions(self):
        """ä¿å­˜ç¾¤ç»„ä¼šè¯ä¿¡æ¯åˆ°æŒä¹…åŒ–å­˜å‚¨"""
        try:
            session_file = os.path.join(self.data_dir, "group_sessions.json")
            with open(session_file, "w", encoding="utf-8") as f:
                json.dump(self.group_sessions, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ç¾¤ç»„ä¼šè¯ä¿¡æ¯æ—¶å‡ºé”™: {e}")

    def load_group_sessions(self):
        """ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½ç¾¤ç»„ä¼šè¯ä¿¡æ¯"""
        try:
            session_file = os.path.join(self.data_dir, "group_sessions.json")
            if os.path.exists(session_file):
                with open(session_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            return {}
        except Exception as e:
            logger.error(f"åŠ è½½ç¾¤ç»„ä¼šè¯ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return {}

    def get_all_checkin_files(self) -> list:
        """è·å–æ‰€æœ‰ç”¨æˆ·çš„æ‰“å¡æ•°æ®æ–‡ä»¶"""
        try:
            files = []
            for file_name in os.listdir(self.data_dir):
                if file_name.startswith("checkin_") and file_name.endswith(".json"):
                    files.append(os.path.join(self.data_dir, file_name))
            return files
        except (OSError, IOError) as e:
            logger.error(f"è¯»å–æ•°æ®æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return []

    def load_user_checkin_data(self, user_id: str, group_id: Optional[str] = None) -> dict:
        """åŠ è½½ç”¨æˆ·æ‰“å¡æ•°æ®"""
        try:
            data_file = self.get_checkin_data_file(user_id, group_id)
            if os.path.exists(data_file):
                with open(data_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    # Ensure strike_count field exists for backward compatibility
                    if "strike_count" not in data:
                        data["strike_count"] = 0
                    return data
            return {"user_id": user_id, "nickname": "", "checkins": [], "total_count": 0, "strike_count": 0}
        except (OSError, IOError, json.JSONDecodeError) as e:
            logger.error(f"åŠ è½½ç”¨æˆ· {user_id} æ•°æ®æ—¶å‡ºé”™: {e}")
            return {"user_id": user_id, "nickname": "", "checkins": [], "total_count": 0, "strike_count": 0}

    def save_user_checkin_data(self, user_id: str, data: dict, group_id: Optional[str] = None):
        """ä¿å­˜ç”¨æˆ·æ‰“å¡æ•°æ®"""
        try:
            data_file = self.get_checkin_data_file(user_id, group_id)
            with open(data_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except (OSError, IOError) as e:
            logger.error(f"ä¿å­˜ç”¨æˆ· {user_id} æ•°æ®æ—¶å‡ºé”™: {e}")

    def reset_group_data(self, group_id: str) -> int:
        """é‡ç½®æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰ç”¨æˆ·æ•°æ®"""
        try:
            all_files = self.get_all_checkin_files()
            reset_count = 0

            # åˆ é™¤æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰ç”¨æˆ·æ•°æ®æ–‡ä»¶
            for file_path in all_files:
                if f"_group_{group_id}.json" in file_path:
                    try:
                        os.remove(file_path)
                        reset_count += 1
                    except (OSError, IOError) as e:
                        logger.error(f"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

            return reset_count
        except Exception as e:
            logger.error(f"é‡ç½®ç¾¤ç»„ {group_id} æ•°æ®æ—¶å‡ºé”™: {e}")
            return 0

    def reset_all_dm_data(self) -> int:
        """é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®"""
        try:
            all_files = self.get_all_checkin_files()
            reset_count = 0

            # åˆ é™¤æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®æ–‡ä»¶
            for file_path in all_files:
                if file_path.endswith("_dm.json"):
                    try:
                        os.remove(file_path)
                        reset_count += 1
                    except (OSError, IOError) as e:
                        logger.error(f"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

            return reset_count
        except Exception as e:
            logger.error(f"é‡ç½®ç§èŠæ•°æ®æ—¶å‡ºé”™: {e}")
            return 0

    def is_trading_day(self, date: datetime) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
        try:
            return self.xcal.is_session(date.date())
        except Exception as e:
            logger.error(f"åˆ¤æ–­äº¤æ˜“æ—¥æ—¶å‡ºé”™: {e}")
            return False

    def get_previous_trading_day(self, date: datetime) -> Optional[datetime]:
        """è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥"""
        try:
            previous_sessions = self.xcal.previous_session(date.date())
            if previous_sessions:
                return datetime.combine(previous_sessions, time())
            return None
        except Exception as e:
            logger.error(f"è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥æ—¶å‡ºé”™: {e}")
            return None

    def get_next_trading_day(self, date: datetime) -> Optional[datetime]:
        """è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥"""
        try:
            next_sessions = self.xcal.next_session(date.date())
            if next_sessions:
                return datetime.combine(next_sessions, time())
            return None
        except Exception as e:
            logger.error(f"è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥æ—¶å‡ºé”™: {e}")
            return None

    def get_time_window_for_context(self, user_id: str, group_id: Optional[str] = None) -> tuple[str, str]:
        """è·å–æŒ‡å®šç”¨æˆ·æˆ–ç¾¤ç»„çš„æ—¶é—´çª—å£é…ç½®"""
        # Check for group-specific configuration
        if group_id and "fupan_checkin_group_time_windows" in self.config:
            group_configs = self.config["fupan_checkin_group_time_windows"]
            if isinstance(group_configs, dict) and group_id in group_configs:
                group_config = group_configs[group_id]
                if isinstance(group_config, dict) and "start_time" in group_config and "end_time" in group_config:
                    return group_config["start_time"], group_config["end_time"]

        # Check for user-specific configuration
        if "fupan_checkin_user_time_windows" in self.config:
            user_configs = self.config["fupan_checkin_user_time_windows"]
            if isinstance(user_configs, dict) and user_id in user_configs:
                user_config = user_configs[user_id]
                if isinstance(user_config, dict) and "start_time" in user_config and "end_time" in user_config:
                    return user_config["start_time"], user_config["end_time"]

        # Fall back to global configuration
        start_time = self.config.get("fupan_checkin_start_time", "15:00")
        end_time = self.config.get("fupan_checkin_end_time", "09:00")
        return start_time, end_time

    def get_current_trading_status(
        self, user_id: str, group_id: Optional[str] = None, now: Optional[datetime] = None
    ) -> dict:
        """è·å–å½“å‰äº¤æ˜“çŠ¶æ€ï¼Œæ”¯æŒ per-group/per-user é…ç½®"""
        if now is None:
            now = datetime.now()
        today = now.date()

        # è·å–ç”¨æˆ·æˆ–ç¾¤ç»„ç‰¹å®šçš„æ—¶é—´çª—å£é…ç½®
        start_time_str, end_time_str = self.get_time_window_for_context(user_id, group_id)

        # åˆ¤æ–­ä»Šå¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        is_today_trading = self.is_trading_day(now)

        if is_today_trading:
            # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
            next_trading_day = self.get_next_trading_day(now)

            start_time = datetime.strptime(start_time_str, "%H:%M").time()
            end_time = datetime.strptime(end_time_str, "%H:%M").time()

            # æ„å»ºæ£€æŸ¥æ—¶é—´çª—å£ (ç›˜åæ—¶é—´çª—å£)
            # ç›˜åå®šä¹‰ä¸ºï¼šTæ—¥æ”¶ç›˜ååˆ°T+1äº¤æ˜“æ—¥å¼€ç›˜å‰
            checkin_start = datetime.combine(today, start_time)
            # å¦‚æœç»“æŸæ—¶é—´æ˜¯ç¬¬äºŒå¤©ï¼Œåˆ™éœ€è¦åŠ ä¸Šä¸€å¤©
            if end_time < start_time:
                checkin_end = datetime.combine(next_trading_day.date() if next_trading_day else today, end_time)
            else:
                checkin_end = datetime.combine(today, end_time)

            # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨æ‰“å¡æ—¶é—´çª—å£å†…
            is_in_checkin_window = checkin_start <= now <= checkin_end

            return {
                "is_trading_day": True,
                "is_in_checkin_window": is_in_checkin_window,
                "checkin_start": checkin_start,
                "checkin_end": checkin_end,
                "next_trading_day": next_trading_day,
                "current_time": now,
            }
        else:
            # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
            next_trading_day = self.get_next_trading_day(now)
            if next_trading_day:
                # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥çš„å‰ä¸€äº¤æ˜“æ—¥ï¼ˆå³æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
                previous_trading_day = self.get_previous_trading_day(next_trading_day)

                if previous_trading_day:
                    # ä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥ä½œä¸ºå‚è€ƒæ¥æ„å»ºæ—¶é—´çª—å£
                    start_time = datetime.strptime(start_time_str, "%H:%M").time()
                    end_time = datetime.strptime(end_time_str, "%H:%M").time()

                    # æ„å»ºæ£€æŸ¥æ—¶é—´çª—å£ï¼ˆåŸºäºæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
                    checkin_start = datetime.combine(previous_trading_day.date(), start_time)
                    checkin_end = datetime.combine(next_trading_day.date(), end_time)

                    # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨æ‰“å¡æ—¶é—´çª—å£å†…
                    is_in_checkin_window = checkin_start <= now <= checkin_end

                    return {
                        "is_trading_day": False,
                        "is_in_checkin_window": is_in_checkin_window,
                        "checkin_start": checkin_start,
                        "checkin_end": checkin_end,
                        "next_trading_day": next_trading_day,
                        "current_time": now,
                    }

            return {
                "is_trading_day": False,
                "is_in_checkin_window": False,
                "checkin_start": None,
                "checkin_end": None,
                "next_trading_day": next_trading_day,
                "current_time": now,
            }

    async def can_user_checkin(
        self, user_id: str, group_id: Optional[str] = None, now: Optional[datetime] = None
    ) -> tuple[bool, str]:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¯ä»¥æ‰“å¡"""
        if now is None:
            now = datetime.now()

        # æ£€æŸ¥æ—¶é—´çª—å£
        status = self.get_current_trading_status(user_id, group_id, now=now)

        if not status["is_in_checkin_window"]:
            if status["checkin_start"] and status["checkin_end"]:
                return False, (
                    f"ä¸åœ¨æ‰“å¡æ—¶é—´çª—å£å†…ï¼Œè¯·åœ¨ {status['checkin_start'].strftime('%H:%M')} - "
                    f"{status['checkin_end'].strftime('%mæœˆ%dæ—¥ %H:%M')} ä¹‹é—´æ‰“å¡"
                )
            else:
                return False, "ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”æœªæ‰¾åˆ°åˆé€‚çš„æ‰“å¡æ—¶é—´çª—å£"

        # æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²æ‰“å¡
        user_data = self.load_user_checkin_data(user_id, group_id)
        today_str = now.strftime("%Y-%m-%d")

        for checkin in user_data["checkins"]:
            if checkin["date"] == today_str:
                # è·å–å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
                current_trading_day = now.date()
                # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™æ˜¾ç¤ºä»Šå¤©çš„æ—¥æœŸä½œä¸ºå½“å‰äº¤æ˜“æ—¥
                if self.is_trading_day(now):
                    current_trading_day_str = current_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")
                else:
                    # å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
                    previous_trading_day = self.get_previous_trading_day(now)
                    current_trading_day_str = (
                        previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if previous_trading_day else "æœªçŸ¥"
                    )

                next_trading_day = self.get_next_trading_day(now)
                next_trading_day_str = next_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if next_trading_day else "æœªçŸ¥"

                return False, f"äº¤æ˜“æ—¥ï¼ˆ{current_trading_day_str}ï¼‰å·²å¤ç›˜\nä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼š{next_trading_day_str}"

        return True, "å¯ä»¥æ‰“å¡"

    def calculate_simple_strike_count(self, checkins: list[dict]) -> int:
        """
        Calculate strike count based on consecutive trading days.
        This is a simplified version that's called when needed, not for every operation.

        Args:
            checkins: All check-ins for the user

        Returns:
            Strike count (consecutive trading days)
        """
        if not checkins:
            return 0

        # Get all unique trading days that were checked in for
        trading_days_checked_in = list({c.get("trading_day") for c in checkins if c.get("trading_day")})

        if not trading_days_checked_in:
            return 0

        # Convert to date objects and sort
        try:
            trading_day_dates = [datetime.strptime(day, "%Y-%m-%d").date() for day in trading_days_checked_in]
            trading_day_dates.sort()
        except ValueError as e:
            logger.error(f"è§£æäº¤æ˜“æ—¥æœŸæ—¶å‡ºé”™: {e}")
            return 0

        # Count consecutive trading days from the most recent
        strike_count = 0
        current_date = trading_day_dates[-1]

        # Go backwards from the most recent trading day
        for trading_day in reversed(trading_day_dates):
            # If this is the first iteration or the trading day is consecutive
            if strike_count == 0 or (current_date - trading_day).days == 1:
                strike_count += 1
                current_date = trading_day
            else:
                # Break if not consecutive
                break

        return strike_count

    # åˆ›å»ºå¤ç›˜å‘½ä»¤
    @filter.command("å¤ç›˜")
    async def fupan_checkin(self, event: AstrMessageEvent, conclusion: str = ""):
        """å¤„ç†å¤ç›˜å‘½ä»¤"""
        # è·å–å½“å‰æ—¶é—´æˆ³
        now = datetime.now()

        # è·å–ç”¨æˆ·å’Œç¾¤ç»„ä¿¡æ¯
        user_id = event.get_sender_id()
        group_id = event.get_group_id() if event.get_group_id() else None

        # è·å–ç”¨æˆ·æ˜µç§°
        nickname = event.get_sender_name()

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰“å¡
        can_checkin, message = await self.can_user_checkin(user_id, group_id, now=now)

        if not can_checkin:
            yield event.plain_result(message)
            return

        # æ‰§è¡Œæ‰“å¡
        user_data = self.load_user_checkin_data(user_id, group_id)
        # æ›´æ–°æ˜µç§°ä¿¡æ¯
        user_data["nickname"] = nickname
        today_str = now.strftime("%Y-%m-%d")
        current_timestamp = now.timestamp()
        current_time_str = now.strftime("%Y-%m-%d %H:%M:%S")

        # Determine which trading day this check-in is for
        trading_day = today_str
        next_trading_day_obj = None

        if not self.is_trading_day(now):
            # If today is not a trading day, this check-in is for the previous trading day
            previous_trading_day = self.get_previous_trading_day(now)
            if previous_trading_day:
                trading_day = previous_trading_day.strftime("%Y-%m-%d")
            # Get the next trading day after the trading day this check-in is for
            next_trading_day_obj = self.get_next_trading_day(previous_trading_day if previous_trading_day else now)
        else:
            # If today is a trading day, get the next trading day
            next_trading_day_obj = self.get_next_trading_day(now)

        next_trading_day_str = next_trading_day_obj.strftime("%Y-%m-%d") if next_trading_day_obj else None

        # æ·»åŠ æ‰“å¡è®°å½•ï¼ŒåŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯
        checkin_record = {
            "date": today_str,
            "timestamp": current_timestamp,
            "trading_day": trading_day,
            "next_trading_day": next_trading_day_str,
            "context": "group" if group_id else "private",
        }

        # æ·»åŠ ç»“è®ºæ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
        if conclusion:
            checkin_record["conclusion"] = conclusion

        # Update strike count efficiently by comparing with previous check-in
        if len(user_data["checkins"]) > 0:
            # Get the previous check-in (the one before we add the new one)
            previous_checkin = user_data["checkins"][-1]
            previous_next_trading_day = previous_checkin.get("next_trading_day")
            previous_trading_day = previous_checkin.get("trading_day")

            # Special case: if this check-in is for the same trading day as the previous one,
            # it doesn't change the strike count (same trading day)
            if trading_day == previous_trading_day:
                # Same trading day, strike count unchanged
                pass
            # If this check-in's trading day matches the previous check-in's next trading day,
            # it's a consecutive strike
            elif previous_next_trading_day and trading_day == previous_next_trading_day:
                user_data["strike_count"] += 1
            else:
                # If not consecutive, reset to 1 (this check-in starts a new streak)
                user_data["strike_count"] = 1
        else:
            # First check-in, start with strike count of 1
            user_data["strike_count"] = 1

        user_data["checkins"].append(checkin_record)
        user_data["total_count"] = len(user_data["checkins"])

        # ä¿å­˜æ•°æ®
        self.save_user_checkin_data(user_id, user_data, group_id)

        # è·å–å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
        current_trading_day = now.date()
        # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™æ˜¾ç¤ºä»Šå¤©çš„æ—¥æœŸä½œä¸ºå½“å‰äº¤æ˜“æ—¥
        if self.is_trading_day(now):
            current_trading_day_str = current_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")
        else:
            # å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
            previous_trading_day = self.get_previous_trading_day(now)
            current_trading_day_str = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if previous_trading_day else "æœªçŸ¥"

        next_trading_day = self.get_next_trading_day(now)
        next_trading_day_str = next_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if next_trading_day else "æœªçŸ¥"

        # ä¿å­˜æ•°æ®
        self.save_user_checkin_data(user_id, user_data, group_id)

        # å¦‚æœæ˜¯ç¾¤ç»„æ¶ˆæ¯ï¼Œä¿å­˜ä¼šè¯ä¿¡æ¯ç”¨äºå¹¿æ’­
        if group_id:
            self.group_sessions[group_id] = event.unified_msg_origin
            self.save_group_sessions()

        # è·å–å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
        current_trading_day = now.date()
        # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™æ˜¾ç¤ºä»Šå¤©çš„æ—¥æœŸä½œä¸ºå½“å‰äº¤æ˜“æ—¥
        if self.is_trading_day(now):
            current_trading_day_str = current_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")
        else:
            # å¦‚æœä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
            previous_trading_day = self.get_previous_trading_day(now)
            current_trading_day_str = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if previous_trading_day else "æœªçŸ¥"

        next_trading_day = self.get_next_trading_day(now)
        next_trading_day_str = next_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥") if next_trading_day else "æœªçŸ¥"

        # å‘é€æˆåŠŸæ¶ˆæ¯ï¼ŒåŒ…å«å½“å‰å’Œä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯
        strike_count = user_data.get("strike_count", 0)
        success_msg = (
            f"âœ… å¤ç›˜æˆåŠŸï¼\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"  å¤ç›˜æ—¶é—´ï¼š{current_time_str}\n"
            f"  ç´¯è®¡å¤ç›˜ï¼š{user_data['total_count']}æ¬¡\n"
            f"  è¿ç»­å¤ç›˜ï¼š{strike_count}è¿å‡»\n"
        )

        # æ·»åŠ ç»“è®ºæ˜¾ç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if conclusion:
            success_msg += f"  å¤ç›˜ç»“è®ºï¼š{conclusion}\n"

        success_msg += (
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n  äº¤æ˜“æ—¥ï¼ˆ{current_trading_day_str}ï¼‰å·²å¤ç›˜\n  ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼š{next_trading_day_str}"
        )
        yield event.plain_result(success_msg)

    # ç»Ÿè®¡å‘½ä»¤
    @filter.command("å¤ç›˜ç»Ÿè®¡", alias={"å¤ç›˜ stats"})
    async def fupan_stats(self, event: AstrMessageEvent):
        """å¤„ç†å¤ç›˜ç»Ÿè®¡å‘½ä»¤"""
        user_id = event.get_sender_id()
        group_id = event.get_group_id() if event.get_group_id() else None
        user_data = self.load_user_checkin_data(user_id, group_id)
        context = "ç¾¤ç»„" if group_id else "ç§èŠ"

        # Get basic statistics
        total_checkins = user_data["total_count"]
        strike_count = user_data.get("strike_count", 0)

        stats_msg = f"ğŸ“ˆ æ‚¨çš„{context}å¤ç›˜ç»Ÿè®¡\n"
        stats_msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        stats_msg += f"  æ€»å¤ç›˜æ¬¡æ•°ï¼š{total_checkins}æ¬¡\n"
        stats_msg += f"  è¿ç»­å¤ç›˜æ¬¡æ•°ï¼š{strike_count}è¿å‡»\n"
        stats_msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

        # Add recent check-in history (last 10)
        if user_data["checkins"]:
            stats_msg += "ğŸ“š æœ€è¿‘å¤ç›˜è®°å½•ï¼š\n"
            # Sort checkins by date descending to show most recent first
            sorted_checkins = sorted(user_data["checkins"], key=lambda x: x["date"], reverse=True)
            for i, checkin in enumerate(sorted_checkins[:10]):  # Show last 10
                date_str = checkin["date"]
                # Format the date to be more readable
                formatted_date = date_str.replace("-", "å¹´", 1).replace("-", "æœˆ", 1) + "æ—¥"
                context_type = "ç¾¤" if checkin.get("context") == "group" else "ç§"

                # Add conclusion if available
                if checkin.get("conclusion"):
                    stats_msg += f"  {i + 1}. {formatted_date} ({context_type})\n     å¤ç›˜ï¼š{checkin['conclusion']}\n"
                else:
                    stats_msg += f"  {i + 1}. {formatted_date} ({context_type})\n"
        else:
            stats_msg += "ğŸ“š æš‚æ— å¤ç›˜è®°å½•\n"

        yield event.plain_result(stats_msg)

    # å¼ºåˆ¶è§¦å‘LLMæ€»ç»“å‘½ä»¤
    @filter.command("å¤ç›˜æ€»ç»“", alias={"å¤ç›˜ summary"})
    @filter.permission_type(filter.PermissionType.ADMIN)  # ä»…é™ç®¡ç†å‘˜æˆ–OPä½¿ç”¨
    async def fupan_summary(self, event: AstrMessageEvent):
        """å¼ºåˆ¶è§¦å‘å½“å‰ç¾¤ç»„çš„LLMå¤ç›˜æ€»ç»“ï¼ˆä»…é™ç®¡ç†å‘˜æˆ–OPï¼‰"""
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¾¤ç»„ä¸­ä½¿ç”¨
        group_id = event.get_group_id()
        if not group_id:
            yield event.plain_result("âŒ è¯¥å‘½ä»¤åªèƒ½åœ¨ç¾¤ç»„ä¸­ä½¿ç”¨")
            return

        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMæ•´åˆ
            use_llm = self.config.get("use_llm_consolidation", True)
            if not use_llm:
                yield event.plain_result("âŒ LLMæ•´åˆåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®ä¸­å¯ç”¨")
                return

            # è·å–å½“å‰æ—¶é—´
            now = datetime.now()

            # è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå¤ç›˜æ—¥æœŸ
            previous_trading_day = self.get_previous_trading_day(now)
            if not previous_trading_day:
                yield event.plain_result("âŒ æ— æ³•è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯")
                return

            review_date = previous_trading_day.strftime("%Y-%m-%d")
            review_date_display = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")

            # ä½¿ç”¨å…±äº«çš„æ€»ç»“ç”Ÿæˆæ–¹æ³•
            summary_content = await self.generate_group_summary(group_id, review_date, review_date_display)

            # ç”Ÿæˆæ€»ç»“æ¶ˆæ¯
            summary_msg = f"ğŸ¤– AIå¤ç›˜æ€»ç»“ ({review_date_display})\n\n{summary_content}"

            yield event.plain_result(summary_msg)

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤ç›˜æ€»ç»“æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"âŒ ç”Ÿæˆå¤ç›˜æ€»ç»“æ—¶å‡ºé”™: {str(e)}")

    # æ’è¡Œå‘½ä»¤
    @filter.command("å¤ç›˜æ’è¡Œ", alias={"å¤ç›˜ rank"})
    async def fupan_rank(self, event: AstrMessageEvent):
        """å¤„ç†å¤ç›˜æ’è¡Œå‘½ä»¤"""
        group_id = event.get_group_id() if event.get_group_id() else None
        all_files = self.get_all_checkin_files()
        rank_data = []

        # æ ¹æ®å½“å‰ç¯å¢ƒè¿‡æ»¤æ–‡ä»¶ï¼ˆç¾¤ç»„æˆ–ç§èŠï¼‰

        for file_path in all_files:
            # åªå¤„ç†ä¸å½“å‰ç¯å¢ƒåŒ¹é…çš„æ–‡ä»¶
            if (group_id and f"_group_{group_id}.json" in file_path) or (
                not group_id and file_path.endswith("_dm.json")
            ):
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        # Ensure strike_count field exists for backward compatibility
                        if "strike_count" not in data:
                            data["strike_count"] = 0
                        rank_data.append(
                            {
                                "user_id": data["user_id"],
                                "nickname": data.get("nickname", data["user_id"]) or data["user_id"],
                                "count": data["strike_count"],  # Use strike count for ranking
                            }
                        )
                except (OSError, IOError, json.JSONDecodeError) as e:
                    logger.error(f"è¯»å–æ’è¡Œæ•°æ®æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                    # Continue with other files

        # æŒ‰è¿ç»­æ‰“å¡æ¬¡æ•°æ’åº
        rank_data.sort(key=lambda x: x["count"], reverse=True)

        context = "ç¾¤ç»„" if group_id else "ç§èŠ"
        rank_msg = f"ğŸ† {context}å¤ç›˜è¿ç»­æ‰“å¡æ’è¡Œ\n"
        rank_msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

        if not rank_data:
            rank_msg += "  æš‚æ— æ•°æ®\n"
        else:
            for i, data in enumerate(rank_data[:10], 1):  # æ˜¾ç¤ºå‰10å
                # å¦‚æœnicknameä¸user_idç›¸åŒæˆ–ä¸ºç©ºï¼Œæ˜¾ç¤º"ç”¨æˆ·{user_id}"æ ¼å¼
                if not data["nickname"] or data["nickname"] == data["user_id"]:
                    display_name = f"ç”¨æˆ·{data['user_id']}"
                else:
                    display_name = data["nickname"]
                rank_msg += f"  {i}. {display_name}: {data['count']}è¿å‡»\n"

        rank_msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

        yield event.plain_result(rank_msg)

    # æ’¤é”€å¤ç›˜å‘½ä»¤
    @filter.command("å¤ç›˜æ’¤é”€", alias={"æ’¤é”€å¤ç›˜"})
    async def fupan_revoke(self, event: AstrMessageEvent):
        """å¤„ç†æ’¤é”€å¤ç›˜å‘½ä»¤"""
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_id = event.get_sender_id()
        group_id = event.get_group_id() if event.get_group_id() else None

        # åŠ è½½ç”¨æˆ·æ•°æ®
        user_data = self.load_user_checkin_data(user_id, group_id)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¤ç›˜è®°å½•
        if not user_data["checkins"]:
            yield event.plain_result("æ‚¨è¿˜æ²¡æœ‰ä»»ä½•å¤ç›˜è®°å½•ï¼Œæ— éœ€æ’¤é”€")
            return

        # è·å–æœ€åä¸€ä¸ªå¤ç›˜è®°å½•
        last_checkin = user_data["checkins"][-1]
        last_checkin_date = last_checkin["date"]
        # Convert timestamp to readable time format
        last_checkin_timestamp = last_checkin["timestamp"]
        last_checkin_time = datetime.fromtimestamp(last_checkin_timestamp).strftime("%Y-%m-%d %H:%M:%S")

        # ç§»é™¤æœ€åä¸€ä¸ªæ‰“å¡è®°å½•
        user_data["checkins"].pop()
        user_data["total_count"] = len(user_data["checkins"])

        # Recalculate strike count after revoking
        # For simplicity in this less frequent operation, we'll recalculate using the full sequence
        if len(user_data["checkins"]) > 0:
            user_data["strike_count"] = self.calculate_simple_strike_count(user_data["checkins"])
        else:
            # No check-ins left, reset strike count
            user_data["strike_count"] = 0

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        self.save_user_checkin_data(user_id, user_data, group_id)

        # å‘é€æˆåŠŸæ¶ˆæ¯
        strike_count = user_data.get("strike_count", 0)
        revoke_msg = (
            f"âœ… å·²æˆåŠŸæ’¤é”€æœ€åä¸€æ¬¡å¤ç›˜\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"  æ’¤é”€è®°å½•ï¼š{last_checkin_date} {last_checkin_time}\n"
            f"  å½“å‰ç´¯è®¡å¤ç›˜ï¼š{user_data['total_count']}æ¬¡\n"
            f"  è¿ç»­å¤ç›˜ï¼š{strike_count}è¿å‡»\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        )
        yield event.plain_result(revoke_msg)

    # æ•°æ®é‡ç½®å‘½ä»¤
    @filter.command("å¤ç›˜é‡ç½®")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def fupan_reset(self, event: AstrMessageEvent, arg: str = ""):
        """å¤„ç†å¤ç›˜æ•°æ®é‡ç½®å‘½ä»¤"""
        group_id = event.get_group_id() if event.get_group_id() else None

        if arg == "ç§èŠ":
            # é‡ç½®æ‰€æœ‰ç§èŠæ•°æ®
            count = self.reset_all_dm_data()
            yield event.plain_result(f"âœ… å·²é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
        elif arg == "å½“å‰ç¾¤ç»„" and group_id:
            # é‡ç½®å½“å‰ç¾¤ç»„æ•°æ®
            count = self.reset_group_data(group_id)
            yield event.plain_result(f"âœ… å·²é‡ç½®ç¾¤ç»„ {group_id} çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
        elif arg.startswith("ç¾¤ç»„"):
            # é‡ç½®æŒ‡å®šç¾¤ç»„æ•°æ®
            target_group_id = arg[2:].strip()  # å»æ‰"ç¾¤ç»„"å‰ç¼€
            if target_group_id:
                count = self.reset_group_data(target_group_id)
                yield event.plain_result(f"âœ… å·²é‡ç½®ç¾¤ç»„ {target_group_id} çš„å¤ç›˜æ•°æ®ï¼Œå…±é‡ç½® {count} ä½ç”¨æˆ·çš„è®°å½•")
            else:
                yield event.plain_result("âŒ è¯·æä¾›è¦é‡ç½®çš„ç¾¤ç»„IDï¼Œä¾‹å¦‚ï¼š/å¤ç›˜é‡ç½® ç¾¤ç»„123456")
        else:
            context = "å½“å‰ç¾¤ç»„" if group_id else "ç§èŠ"
            yield event.plain_result(
                f"ğŸ“ˆ å¤ç›˜æ•°æ®é‡ç½®å‘½ä»¤\n"
                f"ç”¨æ³•ï¼š\n"
                f"  /å¤ç›˜é‡ç½® ç§èŠ - é‡ç½®æ‰€æœ‰ç§èŠç”¨æˆ·æ•°æ®\n"
                f"  /å¤ç›˜é‡ç½® å½“å‰{context} - é‡ç½®{context}æ•°æ®\n"
                f"  /å¤ç›˜é‡ç½® ç¾¤ç»„<ç¾¤å·> - é‡ç½®æŒ‡å®šç¾¤ç»„æ•°æ®\n"
                f"âš ï¸ æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼"
            )

    # å¸®åŠ©å‘½ä»¤
    @filter.command("å¤ç›˜å¸®åŠ©", alias={"å¤ç›˜ help"})
    async def fupan_help(self, event: AstrMessageEvent):
        """å¤„ç†å¤ç›˜å¸®åŠ©å‘½ä»¤"""
        group_id = event.get_group_id() if event.get_group_id() else None
        context = "ç¾¤ç»„" if group_id else "ç§èŠ"

        help_msg = (
            "ğŸ“ˆ å¤ç›˜æ’ä»¶å¸®åŠ©\n"
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            "ğŸ“ åŸºæœ¬å‘½ä»¤ï¼š\n"
            "  /å¤ç›˜ [å¤ç›˜ç»“è®º] - æ¯æ—¥å¤ç›˜ï¼ˆå¯é™„åŠ ç»“è®ºï¼‰\n"
            "  /å¤ç›˜ç»Ÿè®¡ - ä¸ªäººå¤ç›˜ç»Ÿè®¡\n"
            "  /å¤ç›˜æ’è¡Œ - å¤ç›˜æ’è¡Œæ¦œ\n\n"
            "ğŸ§  AIåŠŸèƒ½å‘½ä»¤ï¼š\n"
            "  /å¤ç›˜æ€»ç»“ - å¼ºåˆ¶ç”Ÿæˆå½“å‰ç¾¤ç»„AIå¤ç›˜æ€»ç»“ï¼ˆä»…ç®¡ç†å‘˜/OPï¼‰\n\n"
            "â†©ï¸ å…¶ä»–å‘½ä»¤ï¼š\n"
            "  /å¤ç›˜æ’¤é”€ | /æ’¤é”€å¤ç›˜ - æ’¤é”€æœ€åå¤ç›˜\n"
            f"  /å¤ç›˜é‡ç½® - é‡ç½®æ•°æ®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰\n"
            f"  /å¤ç›˜å¸®åŠ© - æ˜¾ç¤ºæ­¤å¸®åŠ©\n\n"
            f"ç¤ºä¾‹ï¼š/å¤ç›˜ æˆ‘è§‰å¾—æ˜å¤©é«˜å¼€ä½èµ°\n"
            f"å½“å‰ç¯å¢ƒï¼š{context}\n"
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            "ğŸ’¡ æ•°æ®åœ¨ç¾¤èŠå’Œç§èŠä¸­åˆ†å¼€ç»Ÿè®¡"
        )

        yield event.plain_result(help_msg)

    def get_previous_trading_days(self, date: datetime, count: int = 5) -> list:
        """è·å–æŒ‡å®šæ—¥æœŸä¹‹å‰çš„countä¸ªäº¤æ˜“æ—¥"""
        trading_days = []
        current_date = date.date()

        # å‘å‰æŸ¥æ‰¾äº¤æ˜“æ—¥
        while len(trading_days) < count and current_date > date.date().replace(year=date.year - 1):
            if self.xcal.is_session(current_date):
                trading_days.append(current_date)
            current_date = self.xcal.previous_session(current_date).date() if self.xcal.previous_session(current_date) else current_date.replace(day=current_date.day - 1)

        return sorted(trading_days)

    def collect_group_checkins(self, group_id: str, trading_day: str) -> list:
        """æ”¶é›†æŒ‡å®šç¾¤ç»„åœ¨æŒ‡å®šäº¤æ˜“æ—¥çš„å¤ç›˜ä¿¡æ¯"""
        group_checkins = []
        all_files = self.get_all_checkin_files()

        # æŸ¥æ‰¾è¯¥ç¾¤ç»„çš„æ‰€æœ‰ç”¨æˆ·æ•°æ®
        for file_path in all_files:
            if f"_group_{group_id}.json" in file_path:
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        user_data = json.load(f)

                    # æŸ¥æ‰¾è¯¥äº¤æ˜“æ—¥çš„æ‰“å¡è®°å½•
                    for checkin in user_data.get("checkins", []):
                        if checkin.get("trading_day") == trading_day and checkin.get("context") == "group":
                            group_checkins.append({
                                "user_id": user_data["user_id"],
                                "nickname": user_data.get("nickname", user_data["user_id"]),
                                "conclusion": checkin.get("conclusion", ""),
                                "timestamp": checkin.get("timestamp"),
                                "date": checkin.get("date")
                            })
                            break
                except Exception as e:
                    logger.error(f"è¯»å–ç”¨æˆ·æ•°æ®æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                    continue

        return group_checkins

    async def consolidate_with_llm(self, group_checkins: list, group_id: str) -> str:
        """ä½¿ç”¨LLMå¯¹ç¾¤ç»„å¤ç›˜ä¿¡æ¯è¿›è¡Œæ•´åˆå’Œæ€»ç»“"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMæ•´åˆ
            use_llm = self.config.get("use_llm_consolidation", True)
            if not use_llm:
                return ""

            # è·å–LLMæä¾›å•†
            provider_id = self.config.get("llm_provider_id", "")
            if provider_id:
                provider = self.context.get_provider_by_id(provider_id)
            else:
                # ä½¿ç”¨å½“å‰ä¼šè¯çš„é»˜è®¤æä¾›å•†
                provider = self.context.get_using_provider()

            if not provider:
                logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„LLMæä¾›å•†ï¼Œè·³è¿‡æ™ºèƒ½æ•´åˆ")
                return ""

            # æ„å»ºè¾“å…¥å†…å®¹
            checkin_texts = []
            for i, checkin in enumerate(group_checkins, 1):
                nickname = checkin["nickname"] if checkin["nickname"] and checkin["nickname"] != checkin["user_id"] else f"ç”¨æˆ·{checkin['user_id'][:4]}***"
                conclusion = checkin["conclusion"] if checkin["conclusion"] else "æ— å…·ä½“ç»“è®º"
                checkin_texts.append(f"{i}. {nickname}: {conclusion}")

            if not checkin_texts:
                return ""

            input_text = "ä»¥ä¸‹æ˜¯ç¾¤ç»„æˆå‘˜çš„äº¤æ˜“å¤ç›˜å†…å®¹ï¼š\n" + "\n".join(checkin_texts) + "\n\nè¯·å¯¹ä»¥ä¸Šå†…å®¹è¿›è¡Œæ€»ç»“å’Œåˆ†æï¼Œæä¾›ä¸€ä¸ªç®€æ´çš„ç»¼åˆè¯„è¿°ï¼š"

            # è°ƒç”¨LLMè¿›è¡Œæ–‡æœ¬å¤„ç†
            llm_resp = await provider.text_chat(
                prompt=input_text,
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº¤æ˜“åˆ†æå¸ˆï¼Œæ“…é•¿æ€»ç»“å’Œåˆ†æäº¤æ˜“è€…çš„å¤ç›˜å†…å®¹ã€‚è¯·æä¾›ç®€æ´ã€æœ‰ä»·å€¼çš„ç»¼åˆè¯„è¿°ã€‚"
            )

            if llm_resp and hasattr(llm_resp, 'completion_text'):
                return llm_resp.completion_text
            else:
                return ""

        except Exception as e:
            logger.error(f"ä½¿ç”¨LLMæ•´åˆå¤ç›˜ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return ""

    async def generate_daily_review_content(self) -> str:
        """ç”Ÿæˆæ¯æ—¥å¤ç›˜æ’­æŠ¥å†…å®¹"""
        try:
            now = datetime.now()

            # è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå¤ç›˜æ—¥æœŸ
            previous_trading_day = self.get_previous_trading_day(now)
            if not previous_trading_day:
                return "æ— æ³•è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯"

            review_date = previous_trading_day.strftime("%Y-%m-%d")
            review_date_display = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")

            # ç»Ÿè®¡å„ç¾¤ç»„çš„å¤ç›˜æƒ…å†µ
            review_content = f"ğŸ“ˆ æ¯æ—¥å¤ç›˜æ’­æŠ¥ ({review_date_display})\n\n"

            # è·å–æ‰€æœ‰ç¾¤ç»„
            group_ids = set()
            all_files = self.get_all_checkin_files()

            for file_path in all_files:
                if "_group_" in file_path:
                    # ä»æ–‡ä»¶åä¸­æå–ç¾¤ç»„ID
                    parts = file_path.split("_group_")
                    if len(parts) > 1:
                        group_id = parts[1].replace(".json", "")
                        group_ids.add(group_id)

            if not group_ids:
                return "æš‚æ— ç¾¤ç»„å¤ç›˜æ•°æ®"

            # ä¸ºæ¯ä¸ªç¾¤ç»„ç”Ÿæˆå¤ç›˜ç»Ÿè®¡
            for group_id in group_ids:
                group_checkins = self.collect_group_checkins(group_id, review_date)

                if group_checkins:
                    review_content += f"ğŸ“‹ ç¾¤ç»„ {group_id} å¤ç›˜æƒ…å†µ:\n"
                    review_content += f"   å‚ä¸äººæ•°: {len(group_checkins)}äºº\n\n"

                    # æ˜¾ç¤ºå…·ä½“çš„å¤ç›˜å†…å®¹
                    for i, checkin in enumerate(group_checkins, 1):
                        nickname = checkin["nickname"] if checkin["nickname"] and checkin["nickname"] != checkin["user_id"] else f"ç”¨æˆ·{checkin['user_id'][:4]}***"
                        conclusion = checkin["conclusion"] if checkin["conclusion"] else "æ— å…·ä½“ç»“è®º"
                        review_content += f"   {i}. {nickname}: {conclusion}\n"

                    # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ•´åˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    llm_summary = await self.consolidate_with_llm(group_checkins, group_id)
                    if llm_summary:
                        review_content += f"\nğŸ¤– AIæ™ºèƒ½æ€»ç»“:\n   {llm_summary}\n"

                    review_content += "\n"
                else:
                    review_content += f"ğŸ“‹ ç¾¤ç»„ {group_id}: æš‚æ— å¤ç›˜è®°å½•\n\n"

            return review_content.strip()
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¯æ—¥å¤ç›˜æ’­æŠ¥å†…å®¹æ—¶å‡ºé”™: {e}")
            return f"ç”Ÿæˆå¤ç›˜æ’­æŠ¥å†…å®¹æ—¶å‡ºé”™: {str(e)}"

    async def generate_group_summary(self, group_id: str, review_date: str, review_date_display: str) -> str:
        """ä¸ºæŒ‡å®šç¾¤ç»„ç”Ÿæˆå¤ç›˜æ€»ç»“"""
        try:
            # æ”¶é›†ç¾¤ç»„å¤ç›˜ä¿¡æ¯
            group_checkins = self.collect_group_checkins(group_id, review_date)

            if not group_checkins:
                return f"ğŸ“‹ ç¾¤ç»„ {group_id} åœ¨ {review_date_display} æ²¡æœ‰å¤ç›˜è®°å½•"

            # ç”ŸæˆåŸºç¡€ç»Ÿè®¡ä¿¡æ¯
            summary_msg = f"ğŸ“‹ ç¾¤ç»„ {group_id} å¤ç›˜æƒ…å†µ:\n"
            summary_msg += f"   å‚ä¸äººæ•°: {len(group_checkins)}äºº\n\n"

            # æ˜¾ç¤ºå…·ä½“çš„å¤ç›˜å†…å®¹
            for i, checkin in enumerate(group_checkins, 1):
                nickname = checkin["nickname"] if checkin["nickname"] and checkin["nickname"] != checkin["user_id"] else f"ç”¨æˆ·{checkin['user_id'][:4]}***"
                conclusion = checkin["conclusion"] if checkin["conclusion"] else "æ— å…·ä½“ç»“è®º"
                summary_msg += f"   {i}. {nickname}: {conclusion}\n"

            # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½æ•´åˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            llm_summary = await self.consolidate_with_llm(group_checkins, group_id)
            if llm_summary:
                summary_msg += f"\nğŸ¤– AIæ™ºèƒ½æ€»ç»“:\n   {llm_summary}\n"

            return summary_msg

        except Exception as e:
            logger.error(f"ç”Ÿæˆç¾¤ç»„ {group_id} å¤ç›˜æ€»ç»“æ—¶å‡ºé”™: {e}")
            return f"âŒ ç”Ÿæˆå¤ç›˜æ€»ç»“æ—¶å‡ºé”™: {str(e)}"

    async def send_daily_review(self):
        """å‘é€æ¯æ—¥å¤ç›˜æ’­æŠ¥"""
        try:
            # æ£€æŸ¥ä»Šå¤©æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
            now = datetime.now()
            if not self.is_trading_day(now):
                logger.info("ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·³è¿‡å¤ç›˜æ’­æŠ¥")
                return

            # è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå¤ç›˜æ—¥æœŸ
            previous_trading_day = self.get_previous_trading_day(now)
            if not previous_trading_day:
                logger.error("æ— æ³•è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥ä¿¡æ¯")
                return

            review_date = previous_trading_day.strftime("%Y-%m-%d")
            review_date_display = previous_trading_day.strftime("%Yå¹´%mæœˆ%dæ—¥")

            # ç»Ÿè®¡å„ç¾¤ç»„çš„å¤ç›˜æƒ…å†µ
            review_content = f"ğŸ“ˆ æ¯æ—¥å¤ç›˜æ’­æŠ¥ ({review_date_display})\n\n"

            # è·å–æ‰€æœ‰ç¾¤ç»„
            group_ids = set()
            all_files = self.get_all_checkin_files()

            for file_path in all_files:
                if "_group_" in file_path:
                    # ä»æ–‡ä»¶åä¸­æå–ç¾¤ç»„ID
                    parts = file_path.split("_group_")
                    if len(parts) > 1:
                        group_id = parts[1].replace(".json", "")
                        group_ids.add(group_id)

            if not group_ids:
                logger.info("æš‚æ— ç¾¤ç»„å¤ç›˜æ•°æ®ï¼Œè·³è¿‡æ’­æŠ¥")
                return

            # ä¸ºæ¯ä¸ªç¾¤ç»„ç”Ÿæˆå¤ç›˜ç»Ÿè®¡
            has_content = False
            for group_id in group_ids:
                group_summary = await self.generate_group_summary(group_id, review_date, review_date_display)
                if group_summary and "âŒ ç”Ÿæˆå¤ç›˜æ€»ç»“æ—¶å‡ºé”™" not in group_summary:
                    review_content += group_summary + "\n"
                    has_content = True

            if not has_content:
                logger.info("æ²¡æœ‰æœ‰æ•ˆçš„å¤ç›˜æ•°æ®ï¼Œè·³è¿‡æ’­æŠ¥")
                return

            # å‘æ‰€æœ‰æœ‰è®°å½•çš„ç¾¤ç»„å‘é€å¤ç›˜æ’­æŠ¥
            for group_id, session_id in self.group_sessions.items():
                try:
                    # ç¡®ä¿æ˜¯ç¾¤ç»„æ¶ˆæ¯ä¼šè¯
                    if "GroupMessage" in session_id or "group" in session_id.lower():
                        message_chain = MessageChain().message(f"ğŸ“ˆ æ¯æ—¥å¤ç›˜æ’­æŠ¥\n\n{review_content}")
                        success = await self.context.send_message(session_id, message_chain)
                        if success:
                            logger.info(f"æˆåŠŸå‘ç¾¤ç»„ {group_id} å‘é€å¤ç›˜æ’­æŠ¥")
                        else:
                            logger.warning(f"å‘ç¾¤ç»„ {group_id} å‘é€å¤ç›˜æ’­æŠ¥å¤±è´¥")
                except Exception as e:
                    logger.error(f"å‘ç¾¤ç»„ {group_id} å‘é€å¤ç›˜æ’­æŠ¥æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            logger.error(f"å‘é€æ¯æ—¥å¤ç›˜æ’­æŠ¥æ—¶å‡ºé”™: {e}")

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶è°ƒç”¨"""
        # å…³é—­è°ƒåº¦å™¨
        if self.scheduler.running:
            self.scheduler.shutdown()
        logger.info("å¤ç›˜æ‰“å¡æ’ä»¶å·²å¸è½½")
